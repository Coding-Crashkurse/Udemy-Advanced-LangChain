{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "app_dir = os.path.join(os.getcwd(), \"app\")\n",
    "load_dotenv(os.path.join(app_dir, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"How will the weather be in munich today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def fake_weather_api(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Check the weather in a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city where you want to check the weather.\n",
    "\n",
    "    Returns:\n",
    "        str: A description of the current weather in the specified city.\n",
    "    \"\"\"\n",
    "    return \"Sunny, 22°C\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def outdoor_seating_availability(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if outdoor seating is available at a specified restaurant in a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city where you want to check for outdoor seating availability.\n",
    "\n",
    "    Returns:\n",
    "        str: A message stating whether outdoor seating is available or not.\n",
    "    \"\"\"\n",
    "    return \"Outdoor seating is available.\"\n",
    "\n",
    "\n",
    "tools = [fake_weather_api, outdoor_seating_availability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# class WeatherCheck(BaseModel):\n",
    "#     \"\"\"Check the weather in a specified city.\"\"\"\n",
    "\n",
    "#     city: str = Field(..., description=\"Name of the city to check the weather for\")\n",
    "\n",
    "\n",
    "# class OutdoorSeatingCheck(BaseModel):\n",
    "#     \"\"\"Check if outdoor seating is available at a specified restaurant in a given city.\"\"\"\n",
    "\n",
    "#     city: str = Field(..., description=\"Name of the city where the restaurant is located\")\n",
    "\n",
    "\n",
    "# tools = [WeatherCheck, OutdoorSeatingCheck]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"How will the weather be in munich today?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\n",
    "    \"How will the weather be in munich today? I would like to eat outside if possible\"\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        \"How will the weather be in munich today? I would like to eat outside if possible\"\n",
    "    )\n",
    "]\n",
    "llm_output = llm_with_tools.invoke(messages)\n",
    "messages.append(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    \"fake_weather_api\": fake_weather_api,\n",
    "    \"outdoor_seating_availability\": outdoor_seating_availability,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in llm_output.tool_calls:\n",
    "    tool = tool_mapping[tool_call[\"name\"].lower()]\n",
    "    tool_output = tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real third party API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import httpx\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def fake_weather_api(city: str) -> str:\n",
    "    \"\"\"Check the weather in a specified city from a FastAPI endpoint on localhost:8000.\"\"\"\n",
    "    # Make an HTTP GET request to the FastAPI endpoint\n",
    "    response = httpx.get(f\"http://localhost:5566/weather/{city}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"weather\", \"Weather information not available\")\n",
    "    else:\n",
    "        return \"Failed to get weather information\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def outdoor_seating_availability(city: str) -> str:\n",
    "    \"\"\"Check if outdoor seating is available in a specified city from a FastAPI endpoint on localhost:8000.\"\"\"\n",
    "    # Make an HTTP GET request to the FastAPI endpoint\n",
    "    response = httpx.get(f\"http://localhost:5566/outdoor-seating/{city}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\n",
    "            \"outdoor_seating\", \"Outdoor seating information not available\"\n",
    "        )\n",
    "    else:\n",
    "        return \"Failed to get outdoor seating information\"\n",
    "\n",
    "\n",
    "api_tools = [fake_weather_api, outdoor_seating_availability]\n",
    "tool_mapping = {\n",
    "    \"fake_weather_api\": fake_weather_api,\n",
    "    \"outdoor_seating_availability\": outdoor_seating_availability,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def interact_with_llm_and_tools(human_message: str):\n",
    "\n",
    "    llm = ChatOpenAI()\n",
    "    llm_with_tools_new = llm.bind_tools(api_tools)\n",
    "\n",
    "    messages = [human_message]\n",
    "\n",
    "    llm_output = llm_with_tools_new.invoke(messages)\n",
    "    messages.append(llm_output)\n",
    "\n",
    "    print(\"TOOL_CALLS:\", llm_output.tool_calls)\n",
    "\n",
    "    for tool_call in llm_output.tool_calls:\n",
    "        tool_name = tool_call[\"name\"].lower()\n",
    "        tool = tool_mapping.get(tool_name)\n",
    "\n",
    "\n",
    "        if tool:\n",
    "            tool_output = tool.invoke(tool_call[\"args\"])\n",
    "            print(\"TOOL OUTPUT:\", tool_output)\n",
    "            messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "    final_response = llm_with_tools_new.invoke(messages)\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_with_llm_and_tools(\n",
    "    \"How will the weather be in sunnyville today? I would like to eat outside if possible\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_with_llm_and_tools(\n",
    "    \"How will the weather be in rainytown today? I would like to eat outside if possible\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_with_llm_and_tools(\n",
    "    \"How will the weather be in munich today? I would like to eat outside if possible\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_with_llm_and_tools(\"What´s the name of the Dad of the simpsons family?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
