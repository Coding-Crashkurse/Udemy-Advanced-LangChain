{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "app_dir = os.path.join(os.getcwd(), \"app\")\n",
    "load_dotenv(os.path.join(app_dir, \".env\"))\n",
    "\n",
    "loader = DirectoryLoader(\"./data\", glob=\"**/*.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=120,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "db = Chroma.from_documents(chunks, embedding_function)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: list[Document]):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rag_chain_with_source.invoke(input=\"Who is the owner of the restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is that approach bad?\n",
    "\n",
    "You will always retrieve top-k documents and pass them to the model. \n",
    "No matter how relevant the documents are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = result[\"context\"]\n",
    "contents = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for text in contents:\n",
    "    pairs.append([\"Who is the owner of the restaurant\", text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(pairs)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_docs = zip(scores, docs)\n",
    "sorted_docs = sorted(scored_docs, reverse=True)\n",
    "sorted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_docs = [doc for _, doc in sorted_docs][0:2]\n",
    "reranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate that in LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever which retrieves more than 4 documents\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def rerank_documents(input_data):\n",
    "    query = input_data[\"question\"]\n",
    "    docs = input_data[\"context\"]\n",
    "\n",
    "    cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    contents = [doc.page_content for doc in docs]\n",
    "\n",
    "    pairs = [(query, text) for text in contents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "\n",
    "    scored_docs = zip(scores, docs)\n",
    "    sorted_docs = sorted(scored_docs, key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in sorted_docs]\n",
    "\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=RunnableLambda(rerank_documents))\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rag_chain_with_source.invoke(input=\"Who is the owner of the restaurant\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-based Document Compressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "DOCUMENT_EVALUATOR_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"document\", \"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to evaluate the provided document to determine if it is suited to answer the given user question. Assess the document for its relevance to the question, the completeness of information, and the accuracy of the content.\n",
    "\n",
    "    Original question: {question}\n",
    "    Document for Evaluation: {document}\n",
    "    Evaluation Result: <<'True' if the document is suited to answer the question, 'False' if it is not>>\n",
    "\n",
    "    Note: Conclude with a 'True' or 'False' based on your analysis of the document's relevance, completeness, and accuracy in relation to the question.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"The owner is Guivanni\"),\n",
    "    Document(page_content=\"Pizza Salami costs 10$\"),\n",
    "    Document(page_content=\"We close the restaurant at 10p.m each day\"),\n",
    "]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "compression_chain = DOCUMENT_EVALUATOR_PROMPT | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_chain.invoke(\n",
    "    {\"question\": \"Who is the owner of the restaurant\", \"document\": documents[1]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets make that dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_documents(input: dict):\n",
    "    documents = input.get(\"documents\", [])\n",
    "    question = input.get(\"question\")\n",
    "\n",
    "    DOCUMENT_EVALUATOR_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"document\", \"question\"],\n",
    "        template=\"\"\"You are an AI language model assistant. Your task is to evaluate the provided document to determine if it is suited to answer the given user question. Assess the document for its relevance to the question, the completeness of information, and the accuracy of the content.\n",
    "\n",
    "        Original question: {question}\n",
    "        Document for Evaluation: {document}\n",
    "        Evaluation Result: <<'True' if the document is suited to answer the question, 'False' if it is not>>\n",
    "\n",
    "        Note: Conclude with a 'True' or 'False' based on your analysis of the document's relevance, completeness, and accuracy in relation to the question.\"\"\",\n",
    "    )\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    compression_chain = DOCUMENT_EVALUATOR_PROMPT | model | StrOutputParser()\n",
    "\n",
    "    results = []\n",
    "    for document in documents:\n",
    "        evaluation_result = compression_chain.invoke(\n",
    "            {\"document\": document.page_content, \"question\": question}\n",
    "        )\n",
    "        result = evaluation_result == \"True\"\n",
    "        print(result)\n",
    "        results.append(result)\n",
    "\n",
    "    filtered_documents = [doc for doc, res in zip(documents, results) if res]\n",
    "\n",
    "    return filtered_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = {\n",
    "    \"documents\": [\n",
    "        Document(page_content=\"The owner is Guivanni\"),\n",
    "        Document(page_content=\"Pizza Salami costs 10$\"),\n",
    "        Document(page_content=\"We close the restaurant at 10p.m each day\"),\n",
    "    ],\n",
    "    \"question\": \"Who is the owner of the restaurant?\",\n",
    "}\n",
    "\n",
    "results = evaluate_documents(_input)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
